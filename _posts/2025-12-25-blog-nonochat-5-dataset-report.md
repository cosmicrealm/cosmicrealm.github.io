---
title: 'noao-chat-5-è®­ç»ƒå››é˜¶æ®µæ•°æ®æŠ¥å‘Š'
date: 2025-12-25
permalink: /posts/2025/12/2025-12-25-blog-nonochat-5-dataset-report/
tags:
  - llm
---

### nanochat é¡¹ç›®å››é˜¶æ®µè®­ç»ƒæ•°æ®å®Œå…¨æŠ¥å‘Š


[nonochat](https://github.com/karpathy/nanochat)

## ğŸ“‹ æŠ¥å‘Šæ¦‚è§ˆ

æœ¬æŠ¥å‘Šå…¨é¢åˆ†æ nanochat é¡¹ç›®çš„å››ä¸ªè®­ç»ƒé˜¶æ®µï¼ˆBase â†’ Mid â†’ SFT â†’ RLï¼‰ï¼Œæ·±å…¥å‰–ææ¯ä¸ªé˜¶æ®µä½¿ç”¨çš„è®­ç»ƒæ•°æ®ã€éªŒè¯æ•°æ®ã€æ•°æ®é‡ã€æ•°æ®æ¥æºå’Œè¯„ä¼°æŒ‡æ ‡ã€‚

---

## ğŸ¯ å››é˜¶æ®µæ•°æ®æ€»è§ˆè¡¨

| é˜¶æ®µ | è®­ç»ƒæ•°æ®æ¥æº | è®­ç»ƒæ•°æ®é‡ | éªŒè¯æ•°æ®æ¥æº | éªŒè¯æ•°æ®é‡ | ä¸»è¦è¯„ä¼°æŒ‡æ ‡ |
|------|-------------|-----------|------------|-----------|------------|
| **Base** | FineWeb-Edu | 100B tokens | FineWeb-Edu (æœ€åä¸€ä¸ªshard) | ~10M tokens | BPB + CORE Metric |
| **Mid** | 7ä¸ªä»»åŠ¡æ··åˆ | 848K å¯¹è¯ | 3ä¸ªä»»åŠ¡æ··åˆ | 39K å¯¹è¯ | BPB |
| **SFT** | 7ä¸ªä»»åŠ¡æ··åˆ | 23K å¯¹è¯ | SmolTalk | 24K å¯¹è¯ | Loss + MMLU/ARCå‡†ç¡®ç‡ |
| **RL** | GSM8K | 7.5K é—®é¢˜ | GSM8K | 1.3K é—®é¢˜ | Pass@k (k=1,4,16) |

---

## ğŸ“Š ç¬¬ä¸€é˜¶æ®µï¼šBase Trainingï¼ˆåŸºç¡€é¢„è®­ç»ƒï¼‰

### è®­ç»ƒæ•°æ®

**æ•°æ®é›†åç§°ï¼šFineWeb-Edu-100B**

```python
# æ•°æ®æºé…ç½®
BASE_URL = "https://huggingface.co/datasets/karpathy/fineweb-edu-100b-shuffle/resolve/main"
MAX_SHARD = 1822  # å…± 1823 ä¸ª shard (shard_00000 åˆ° shard_01822)
```

#### æ•°æ®è§„æ¨¡
- **Token æ•°é‡**ï¼š~100B tokens
- **æ–‡ä»¶æ•°é‡**ï¼š1823 ä¸ª Parquet æ–‡ä»¶
- **æ–‡ä»¶æ ¼å¼**ï¼š`shard_00000.parquet` ~ `shard_01822.parquet`
- **å­˜å‚¨å¤§å°**ï¼šæ¯ä¸ªæ–‡ä»¶çº¦ 50-100 MB
- **æ•°æ®åˆ‡åˆ†**ï¼šå‰ 1822 ä¸ªæ–‡ä»¶ç”¨äºè®­ç»ƒï¼Œæœ€å 1 ä¸ªæ–‡ä»¶ç”¨äºéªŒè¯

#### æ•°æ®ç‰¹ç‚¹
- **æ¥æº**ï¼šé«˜è´¨é‡æ•™è‚²ç½‘é¡µï¼ˆFineWeb-Edu å­é›†ï¼‰
- **è¯­è¨€**ï¼šä¸»è¦æ˜¯è‹±æ–‡
- **å†…å®¹ç±»å‹**ï¼šç½‘é¡µæŠ“å–çš„çº¯æ–‡æœ¬
- **é¢„å¤„ç†**ï¼š
  - å·²ç»è¿‡è´¨é‡è¿‡æ»¤ï¼ˆæ•™è‚²ç›¸å…³å†…å®¹ï¼‰
  - å·²å»é‡å’Œæ¸…æ´—
  - å­˜å‚¨æ ¼å¼ï¼šParquet æ–‡ä»¶ï¼Œæ¯è¡ŒåŒ…å« `text` å­—æ®µ

#### æ•°æ®åŠ è½½æœºåˆ¶

```python
# ä» dataset.py
def parquets_iter_batched(split, start=0, step=1):
    """
    - split: "train" æˆ– "val"
    - start/step: ç”¨äº DDP åˆ†å¸ƒå¼è®­ç»ƒ
    """
    parquet_paths = list_parquet_files()
    
    if split == "train":
        parquet_paths = parquet_paths[:-1]  # å‰ 1822 ä¸ªæ–‡ä»¶
    else:  # val
        parquet_paths = parquet_paths[-1:]  # æœ€å 1 ä¸ªæ–‡ä»¶
    
    for filepath in parquet_paths:
        pf = pq.ParquetFile(filepath)
        for rg_idx in range(start, pf.num_row_groups, step):
            rg = pf.read_row_group(rg_idx)
            texts = rg.column('text').to_pylist()
            yield texts
```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… **æµå¼è¯»å–**ï¼šä¸éœ€è¦ä¸€æ¬¡æ€§åŠ è½½å…¨éƒ¨æ•°æ®åˆ°å†…å­˜
- âœ… **Row Group çº§åˆ«**ï¼šåˆ©ç”¨ Parquet çš„ row group ç‰¹æ€§å®ç°ç²¾ç»†åŒ–åˆ†å¸ƒå¼è¯»å–
- âœ… **DDP å‹å¥½**ï¼šé€šè¿‡ `start` å’Œ `step` å‚æ•°å®ç°å¤šå¡è®­ç»ƒæ—¶çš„æ•°æ®åˆ†å‰²

### éªŒè¯æ•°æ®

**æ•°æ®é›†ï¼šFineWeb-Eduï¼ˆéªŒè¯é›†ï¼‰**

#### è§„æ¨¡
- **æ–‡ä»¶æ•°é‡**ï¼š1 ä¸ª Parquet æ–‡ä»¶ï¼ˆ`shard_01822.parquet`ï¼‰
- **Token æ•°é‡**ï¼šçº¦ 10-20M tokens
- **è¯„ä¼°é¢‘ç‡**ï¼šæ¯ 250 æ­¥ï¼ˆå¯é…ç½® `--eval_every=250`ï¼‰
- **è¯„ä¼° Token æ•°**ï¼š20 Ã— 524288 = 10,485,760 tokensï¼ˆå¯é…ç½® `--eval_tokens`ï¼‰

#### è¯„ä¼°æŒ‡æ ‡ 1ï¼šBPB (Bits Per Byte)

**å…¬å¼**ï¼š
```
BPB = Loss / ln(2) / bytes_per_token
```

**è®¡ç®—è¿‡ç¨‹**ï¼š
```python
# ä» loss_eval.py
def evaluate_bpb(model, val_loader, eval_steps, token_bytes):
    total_loss = 0.0
    total_tokens = 0
    
    for _ in range(eval_steps):
        inputs, targets = next(val_loader)  # (B, T)
        loss = model(inputs, targets)  # CrossEntropy loss
        
        # ç»Ÿè®¡é padding token çš„æ•°é‡
        num_tokens = (targets != -1).sum()
        total_loss += loss * num_tokens
        total_tokens += num_tokens
    
    avg_loss = total_loss / total_tokens  # å¹³å‡ loss
    
    # token_bytes: (vocab_size,) æ¯ä¸ª token å¯¹åº”çš„å­—èŠ‚æ•°
    bytes_per_token = token_bytes[targets[targets != -1]].float().mean()
    
    # BPB = Loss è½¬æ¢ä¸º bitsï¼Œå†é™¤ä»¥æ¯ token çš„å­—èŠ‚æ•°
    bpb = avg_loss / math.log(2) / bytes_per_token
    
    return bpb
```

**BPB çš„ä¼˜åŠ¿**ï¼š
- ğŸ¯ **Tokenizer æ— å…³**ï¼šä¸åŒçš„ tokenizer å¯ä»¥æ¯”è¾ƒ
- ğŸ¯ **å­—èŠ‚çº§å½’ä¸€åŒ–**ï¼šæ›´å…¬å¹³çš„å‹ç¼©ç‡åº¦é‡
- ğŸ¯ **å¯è§£é‡Šæ€§**ï¼šè¡¨ç¤ºæ¯ä¸ªå­—èŠ‚éœ€è¦å¤šå°‘ bits æ¥ç¼–ç 

#### è¯„ä¼°æŒ‡æ ‡ 2ï¼šCORE Metric

**CORE = Comprehensive Reasoning Evaluation**

CORE Metric æ˜¯ 9 ä¸ªä¸åŒä»»åŠ¡çš„å¹³å‡è¡¨ç°ï¼ˆç»è¿‡ centered å½’ä¸€åŒ–ï¼‰ï¼š

| ä»»åŠ¡ç±»å‹ | ä»»åŠ¡åç§° | æ ·æœ¬æ•°é‡ | æµ‹è¯•å†…å®¹ |
|---------|---------|---------|---------|
| å¤šé€‰é¢˜ | ARC-Easy | 500 | å°å­¦ç§‘å­¦æ¨ç† |
| å¤šé€‰é¢˜ | ARC-Challenge | 500 | ä¸­å­¦ç§‘å­¦æ¨ç† |
| å¤šé€‰é¢˜ | MMLU | 500 | 57ä¸ªå­¦ç§‘çš„å¤šé€‰é¢˜ |
| å¤šé€‰é¢˜ | HellaSwag | 500 | å¸¸è¯†æ¨ç†ï¼ˆå®Œæˆå¥å­ï¼‰ |
| Schema | GSM8K (Zero-Shot) | 500 | æ•°å­¦é—®é¢˜ï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼‰ |
| LM | GPQA | 500 | ç ”ç©¶ç”Ÿçº§åˆ«çš„ç§‘å­¦é—®é¢˜ |
| LM | MuSR | 500 | å¤šæ­¥æ¨ç† |
| LM | Lambada | 500 | è¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹æœ€åä¸€ä¸ªè¯ï¼‰ |
| LM | SQuAD | 500 | é˜…è¯»ç†è§£ |

**è¯„ä¼°é¢‘ç‡**ï¼š
- æ¯ 2000 æ­¥ï¼ˆå¯é…ç½® `--core_metric_every=2000`ï¼‰
- æ¯ä¸ªä»»åŠ¡æœ€å¤šè¯„ä¼° 500 ä¸ªæ ·æœ¬ï¼ˆå¯é…ç½® `--core_metric_max_per_task=500`ï¼‰

**CORE Metric è®¡ç®—**ï¼š
```python
# ä» base_eval.py
def evaluate_model(model, tokenizer, device, max_per_task=500):
    results = {}
    
    # è¯„ä¼° 9 ä¸ªä»»åŠ¡
    for task_name, task_config in core_tasks.items():
        accuracy = evaluate_task(
            model, 
            tokenizer, 
            task_config, 
            max_examples=max_per_task
        )
        results[task_name] = accuracy
    
    # Centered normalizationï¼ˆå‡å»åŸºçº¿æ¨¡å‹çš„è¡¨ç°ï¼‰
    centered_results = {}
    for task_name, accuracy in results.items():
        baseline = BASELINES[task_name]  # åŸºçº¿æ¨¡å‹ï¼ˆå¦‚ random guessï¼‰
        centered_results[task_name] = accuracy - baseline
    
    # CORE Metric = æ‰€æœ‰ centered ç»“æœçš„å¹³å‡å€¼
    core_metric = sum(centered_results.values()) / len(centered_results)
    
    return {
        "core_metric": core_metric,
        "centered_results": centered_results,
        "raw_results": results
    }
```

**CORE Metric çš„æ„ä¹‰**ï¼š
- ğŸ“Š **å¤šæ ·æ€§**ï¼šè¦†ç›–æ¨ç†ã€å¸¸è¯†ã€æ•°å­¦ã€é˜…è¯»ç†è§£ç­‰å¤šä¸ªç»´åº¦
- ğŸ“Š **åŸºçº¿å½’ä¸€åŒ–**ï¼šå‡å»éšæœºçŒœæµ‹çš„è¡¨ç°ï¼Œæ›´å‡†ç¡®åæ˜ æ¨¡å‹èƒ½åŠ›
- ğŸ“Š **æ—©æœŸæŒ‡æ ‡**ï¼šåœ¨é¢„è®­ç»ƒé˜¶æ®µå°±èƒ½çœ‹åˆ°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›

### è®­ç»ƒé…ç½®

```python
# base_train.py é»˜è®¤é…ç½®
depth = 20                    # æ¨¡å‹æ·±åº¦
max_seq_len = 2048           # æœ€å¤§åºåˆ—é•¿åº¦
device_batch_size = 32       # æ¯å¼ å¡çš„ batch size
total_batch_size = 524288    # æ€» batch sizeï¼ˆtokensï¼‰
target_param_data_ratio = 20 # Chinchilla ratioï¼ˆæ•°æ®:å‚æ•° = 20:1ï¼‰

# å­¦ä¹ ç‡
embedding_lr = 0.2           # Embedding å±‚ï¼ˆAdamWï¼‰
unembedding_lr = 0.004       # Unembedding å±‚ï¼ˆAdamWï¼‰
matrix_lr = 0.02             # å…¶ä»–çŸ©é˜µå‚æ•°ï¼ˆMuonï¼‰
weight_decay = 0.0

# å­¦ä¹ ç‡è°ƒåº¦
warmup_ratio = 0.0           # é¢„çƒ­é˜¶æ®µå æ¯”
warmdown_ratio = 0.2         # è¡°å‡é˜¶æ®µå æ¯”
final_lr_frac = 0.0          # æœ€ç»ˆå­¦ä¹ ç‡å€æ•°
```

**è®­ç»ƒé•¿åº¦è®¡ç®—**ï¼š
```python
num_params = æ¨¡å‹å‚æ•°é‡ï¼ˆä¾‹å¦‚ 120Mï¼‰
target_tokens = 20 * num_params  # Chinchilla ratio
num_iterations = target_tokens // total_batch_size

# ä¾‹å¦‚ï¼š120M å‚æ•°çš„æ¨¡å‹
# target_tokens = 20 * 120M = 2.4B tokens
# num_iterations = 2.4B / 524288 â‰ˆ 4577 steps
```

---

## ğŸ“Š ç¬¬äºŒé˜¶æ®µï¼šMid Trainingï¼ˆä¸­é—´è®­ç»ƒï¼‰

### è®­ç»ƒæ•°æ®

**æ•°æ®é›†ï¼šTaskMixtureï¼ˆ7ä¸ªä»»åŠ¡æ··åˆï¼‰**

#### æ•°æ®ç»„æˆ

```python
# ä» mid_train.py
train_dataset = TaskMixture([
    SmolTalk(split="train"),                 # 460K å¯¹è¯
    MMLU(subset="auxiliary_train", split="train"),  # 100K é—®é¢˜
    GSM8K(subset="main", split="train"),     # 8K é—®é¢˜
    CustomJSON(filepath=identity_conversations_filepath),  # 1K å¯¹è¯
    CustomJSON(filepath=identity_conversations_filepath),  # 1K å¯¹è¯ï¼ˆ2 epochsï¼‰
    SimpleSpelling(size=200000, split="train"),  # 200K å¯¹è¯
    SpellingBee(size=80000, split="train"),  # 80K å¯¹è¯
])
# æ€»è®¡ï¼š460K + 100K + 8K + 1K + 1K + 200K + 80K = 850K å¯¹è¯
```

#### å„ä»»åŠ¡è¯¦æƒ…

##### 1. SmolTalk - é€šç”¨å¯¹è¯ï¼ˆ460Kï¼‰

**æ¥æº**ï¼šHuggingFaceTB/smol-smoltalk
- **å†…å®¹**ï¼šé«˜è´¨é‡çš„å¤šè½®å¯¹è¯
- **æ ¼å¼**ï¼šæ ‡å‡†å¯¹è¯æ ¼å¼ï¼ˆå¯é€‰ system message + user/assistant äº¤æ›¿ï¼‰
- **ç”¨é€”**ï¼šæ•™ä¼šæ¨¡å‹è¿›è¡Œè‡ªç„¶çš„å¤šè½®å¯¹è¯

**æ•°æ®ç¤ºä¾‹**ï¼š
```json
{
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is the capital of France?"},
    {"role": "assistant", "content": "The capital of France is Paris."}
  ]
}
```

##### 2. MMLU - å¤šå­¦ç§‘å¤šé€‰é¢˜ï¼ˆ100Kï¼‰

**æ¥æº**ï¼šauxiliary_train å­é›†
- **å†…å®¹**ï¼šä» ARCã€MC_TESTã€OBQAã€RACE æŠ½å–çš„å¤šé€‰é¢˜
- **æ ¼å¼**ï¼š4é€‰1 å¤šé€‰é¢˜
- **ç”¨é€”**ï¼šæ•™ä¼šæ¨¡å‹ç†è§£å’Œå›ç­”å¤šé€‰é¢˜æ ¼å¼

**æ•°æ®ç¤ºä¾‹**ï¼š
```python
{
  "messages": [
    {
      "role": "user",
      "content": "Multiple Choice question: What is the chemical symbol for gold?\n- Gold=A\n- Au=B\n- Ag=C\n- Fe=D\n\nRespond only with the letter of the correct answer."
    },
    {
      "role": "assistant",
      "content": "B"
    }
  ]
}
```

##### 3. GSM8K - æ•°å­¦æ¨ç†ï¼ˆ8Kï¼‰

**æ¥æº**ï¼šGSM8K main è®­ç»ƒé›†
- **å†…å®¹**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **æ ¼å¼**ï¼šå¯¹è¯å¼ï¼Œå¸¦å·¥å…·è°ƒç”¨ï¼ˆcalculatorï¼‰
- **ç”¨é€”**ï¼šæ•™ä¼šæ¨¡å‹è¿›è¡Œæ•°å­¦æ¨ç†å’Œä½¿ç”¨å·¥å…·

**æ•°æ®ç¤ºä¾‹**ï¼š
```json
{
  "messages": [
    {
      "role": "user",
      "content": "Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. How many does she sell at the farmers' market daily?"
    },
    {
      "role": "assistant",
      "content": "Let me calculate this step by step.\n<tool>calculator(16-3-4)</tool>\nShe sells 9 eggs daily."
    }
  ]
}
```

##### 4. CustomJSON - èº«ä»½å¯¹è¯ï¼ˆ2Kï¼Œ2 epochsï¼‰

**æ¥æº**ï¼šidentity_conversations.jsonlï¼ˆé¡¹ç›®è‡ªå®šä¹‰ï¼‰
- **å†…å®¹**ï¼šå…³äºæ¨¡å‹èº«ä»½ã€èƒ½åŠ›ã€é™åˆ¶çš„å¯¹è¯
- **æ ¼å¼**ï¼šæ ‡å‡†å¯¹è¯æ ¼å¼
- **ç”¨é€”**ï¼šæ•™ä¼šæ¨¡å‹è®¤è¯†è‡ªå·±çš„èº«ä»½ï¼ˆ"I am nanochat"ï¼‰
- **ç‰¹æ®Šå¤„ç†**ï¼š2 epochsï¼ˆå‡ºç°ä¸¤æ¬¡ï¼‰ä»¥å¼ºåŒ–è®°å¿†

**æ•°æ®ç¤ºä¾‹**ï¼š
```json
{
  "messages": [
    {
      "role": "user",
      "content": "What is your name?"
    },
    {
      "role": "assistant",
      "content": "I am nanochat, an AI assistant created to help answer questions and have conversations."
    }
  ]
}
```

##### 5. SimpleSpelling - ç®€å•æ‹¼å†™ï¼ˆ200Kï¼‰

**æ¥æº**ï¼šç¨‹åºåŒ–ç”Ÿæˆ
- **å†…å®¹**ï¼šç®€å•æ‹¼å†™ä»»åŠ¡ï¼ˆå¦‚"spell the word 'apple'"ï¼‰
- **æ ¼å¼**ï¼šå¯¹è¯å¼
- **ç”¨é€”**ï¼šæ•™ä¼šæ¨¡å‹ç†è§£å’Œå¤„ç†å­—ç¬¦çº§ä»»åŠ¡

**æ•°æ®ç¤ºä¾‹**ï¼š
```json
{
  "messages": [
    {
      "role": "user",
      "content": "Spell the word 'hello'."
    },
    {
      "role": "assistant",
      "content": "h-e-l-l-o"
    }
  ]
}
```

##### 6. SpellingBee - å­—æ¯è®¡æ•°ï¼ˆ80Kï¼‰

**æ¥æº**ï¼šç¨‹åºåŒ–ç”Ÿæˆ
- **å†…å®¹**ï¼šå­—æ¯è®¡æ•°ä»»åŠ¡ï¼ˆå¦‚"how many 'r' in 'strawberry'?"ï¼‰
- **æ ¼å¼**ï¼šå¯¹è¯å¼ï¼Œå¸¦å·¥å…·è°ƒç”¨
- **ç”¨é€”**ï¼šæ•™ä¼šæ¨¡å‹è¿›è¡Œç»†ç²’åº¦çš„å­—ç¬¦çº§æ¨ç†

**æ•°æ®ç¤ºä¾‹**ï¼š
```json
{
  "messages": [
    {
      "role": "user",
      "content": "How many times does the letter 'r' appear in the word 'strawberry'?"
    },
    {
      "role": "assistant",
      "content": "<tool>count_letter('strawberry', 'r')</tool>\nThe letter 'r' appears 3 times in 'strawberry'."
    }
  ]
}
```

#### æ•°æ®æ··åˆç­–ç•¥

```python
# TaskMixture å®ç°ï¼ˆä» tasks/common.pyï¼‰
class TaskMixture(Task):
    def __init__(self, tasks):
        self.tasks = tasks
        self.lengths = [len(task) for task in tasks]
        
        # æ„å»ºç´¢å¼•æ˜ å°„
        self.index_map = []
        for task_idx, task_length in enumerate(self.lengths):
            for local_idx in range(task_length):
                self.index_map.append((task_idx, local_idx))
        
        # ç¡®å®šæ€§ shuffleï¼ˆseed=42ï¼‰
        rng = random.Random(42)
        rng.shuffle(self.index_map)
    
    def get_example(self, index):
        task_idx, local_idx = self.index_map[index]
        return self.tasks[task_idx][local_idx]
```

**æ··åˆç‰¹ç‚¹**ï¼š
- âœ… **ç¡®å®šæ€§ shuffle**ï¼šä½¿ç”¨å›ºå®š seed=42ï¼Œä¿è¯å¯å¤ç°
- âœ… **ä»»åŠ¡å‡åŒ€åˆ†å¸ƒ**ï¼šä¸åŒä»»åŠ¡çš„æ ·æœ¬åœ¨æ•´ä¸ª epoch ä¸­å‡åŒ€åˆ†å¸ƒ
- âœ… **æ”¯æŒ oversampling**ï¼šå¯ä»¥å¤šæ¬¡æ·»åŠ åŒä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚ identity_conversations Ã— 2ï¼‰

### éªŒè¯æ•°æ®

**æ•°æ®é›†ï¼šTaskMixtureï¼ˆ3ä¸ªä»»åŠ¡æ··åˆï¼‰**

```python
# ä» mid_train.py
val_dataset = TaskMixture([
    SmolTalk(split="test"),           # 24K å¯¹è¯
    MMLU(subset="all", split="test", stop=5200),  # 5.2K é—®é¢˜ï¼ˆä» 14K ä¸­å–ï¼‰
    GSM8K(subset="main", split="test", stop=420),  # 420 é—®é¢˜ï¼ˆä» 1.3K ä¸­å–ï¼‰
])
# æ€»è®¡ï¼š24K + 5.2K + 0.42K â‰ˆ 30K å¯¹è¯
```

**éªŒè¯æ•°æ®ç‰¹ç‚¹**ï¼š
- ğŸ“Š **æ¯”ä¾‹åŒ¹é…**ï¼šéªŒè¯é›†çš„ä»»åŠ¡æ¯”ä¾‹ä¸è®­ç»ƒé›†ç›¸ä¼¼
- ğŸ“Š **æ•°æ®åˆ‡ç‰‡**ï¼šMMLU å’Œ GSM8K ä½¿ç”¨ `stop` å‚æ•°æ§åˆ¶æ ·æœ¬æ•°é‡
- ğŸ“Š **è¯„ä¼°æŒ‡æ ‡**ï¼šBPBï¼ˆä¸ Base è®­ç»ƒç›¸åŒçš„æŒ‡æ ‡ï¼‰

#### è¯„ä¼°é…ç½®

```python
# ä» mid_train.py
eval_every = 150              # æ¯ 150 æ­¥è¯„ä¼°ä¸€æ¬¡
eval_tokens = 20 * 524288     # è¯„ä¼° 10M tokens
```

### è®­ç»ƒé…ç½®

```python
# mid_train.py é»˜è®¤é…ç½®
max_seq_len = 2048
device_batch_size = 32
total_batch_size = 524288    # ä¸ Base è®­ç»ƒç›¸åŒ

# å­¦ä¹ ç‡ï¼ˆä¸ Base è®­ç»ƒç›¸åŒï¼‰
unembedding_lr = 0.004
embedding_lr = 0.2
matrix_lr = 0.02
weight_decay = 0.0
init_lr_frac = 1.0           # åˆå§‹ LR å€æ•°

# å­¦ä¹ ç‡è°ƒåº¦ï¼ˆä¸ Base ä¸åŒï¼ï¼‰
def get_lr_multiplier(progress):
    # å‰ 80% ä¸è¡°å‡ï¼Œå 20% çº¿æ€§è¡°å‡åˆ° 0
    return 1 if progress < 0.8 else 1 - (progress - 0.8) / 0.2
```

**è®­ç»ƒé•¿åº¦**ï¼š
- **é»˜è®¤**ï¼š1 epoch over 850K å¯¹è¯
- **è®¡ç®—**ï¼šnum_iterations = ç”±ç”¨æˆ·æŒ‡å®šæˆ–è‡ªåŠ¨è®¡ç®—ï¼ˆåŸºäº dataset_sizeï¼‰

---

## ğŸ“Š ç¬¬ä¸‰é˜¶æ®µï¼šSFT Trainingï¼ˆç›‘ç£å¾®è°ƒï¼‰

### è®­ç»ƒæ•°æ®

**æ•°æ®é›†ï¼šTaskMixtureï¼ˆ7ä¸ªä»»åŠ¡æ··åˆï¼‰**

#### æ•°æ®ç»„æˆ

```python
# ä» chat_sft.py
train_ds = TaskMixture([
    ARC(subset="ARC-Easy", split="train"),      # 2.3K å¯¹è¯
    ARC(subset="ARC-Challenge", split="train"), # 1.1K å¯¹è¯
    GSM8K(subset="main", split="train"),        # 8K å¯¹è¯
    SmolTalk(split="train", stop=10_000),       # 10K å¯¹è¯
    CustomJSON(filepath=identity_conversations_filepath),  # 1K å¯¹è¯
    SimpleSpelling(size=300, split="train"),    # 300 å¯¹è¯
    SpellingBee(size=300, split="train"),       # 300 å¯¹è¯
])
# æ€»è®¡ï¼š2.3K + 1.1K + 8K + 10K + 1K + 0.3K + 0.3K = 23K å¯¹è¯
```

#### æ•°æ®è§„æ¨¡å¯¹æ¯”

| ä»»åŠ¡ | Mid Training | SFT Training | å˜åŒ–è¯´æ˜ |
|------|-------------|--------------|---------|
| SmolTalk | 460K | 10K | å¤§å¹…å‡å°‘ï¼Œåªç”¨ 2% |
| MMLU | 100K (auxiliary) | 0 | å®Œå…¨ç§»é™¤ |
| ARC | 0 | 3.4K (Easy+Challenge) | æ–°å¢ |
| GSM8K | 8K | 8K | ä¿æŒä¸å˜ |
| Identity | 2K | 1K | å‡åŠ |
| SimpleSpelling | 200K | 300 | å¤§å¹…å‡å°‘ |
| SpellingBee | 80K | 300 | å¤§å¹…å‡å°‘ |
| **æ€»è®¡** | **850K** | **23K** | **å‡å°‘ 97%** |

**æ•°æ®å˜åŒ–çš„åŸå› **ï¼š
- ğŸ¯ **ç²¾ç®€é«˜æ•ˆ**ï¼šSFT åªéœ€è¦å°‘é‡é«˜è´¨é‡æ•°æ®
- ğŸ¯ **å»é™¤é‡å¤**ï¼šæ¨¡å‹åœ¨ Mid é˜¶æ®µå·²ç»å­¦ä¼šäº†å¯¹è¯æ ¼å¼
- ğŸ¯ **èšç„¦èƒ½åŠ›**ï¼šé‡ç‚¹æ”¾åœ¨æ¨ç†èƒ½åŠ›ï¼ˆARCã€GSM8Kï¼‰
- ğŸ¯ **é˜²æ­¢è¿‡æ‹Ÿåˆ**ï¼šå°æ•°æ®é›†é…åˆå°å­¦ä¹ ç‡ï¼ˆ0.02xï¼‰

#### ARC ä»»åŠ¡è¯¦æƒ…

**æ¥æº**ï¼šAI2 Reasoning Challenge
- **ARC-Easy**ï¼š2.3K å°å­¦çº§åˆ«ç§‘å­¦æ¨ç†é¢˜
- **ARC-Challenge**ï¼š1.1K ä¸­å­¦çº§åˆ«ç§‘å­¦æ¨ç†é¢˜
- **æ ¼å¼**ï¼š4é€‰1 å¤šé€‰é¢˜
- **ç”¨é€”**ï¼šæå‡ç§‘å­¦æ¨ç†èƒ½åŠ›

**æ•°æ®ç¤ºä¾‹**ï¼š
```python
{
  "messages": [
    {
      "role": "user",
      "content": "Multiple Choice question: Which of the following is a renewable resource?\n- Coal=A\n- Oil=B\n- Solar energy=C\n- Natural gas=D\n\nRespond only with the letter of the correct answer."
    },
    {
      "role": "assistant",
      "content": "C"
    }
  ]
}
```

### SFT çš„æ ¸å¿ƒåˆ›æ–°ï¼šMask æœºåˆ¶

**å…³é”®é—®é¢˜**ï¼šåœ¨å¯¹è¯è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬åªæƒ³è®©æ¨¡å‹å­¦ä¹  assistant çš„å›å¤ï¼Œè€Œä¸æ˜¯ user çš„é—®é¢˜ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ mask æ ‡è®°å“ªäº› token éœ€è¦è®¡ç®— lossã€‚

#### Mask ç”Ÿæˆè¿‡ç¨‹

```python
# ä» tokenizer.py
def render_conversation(self, conversation):
    """
    è¿”å›ï¼š
    - ids: List[int]ï¼Œå®Œæ•´çš„ token åºåˆ—
    - mask: List[int]ï¼Œ0/1 æ ‡è®°ï¼ˆ1=è®¡ç®—lossï¼Œ0=ä¸è®¡ç®—ï¼‰
    """
    ids = []
    mask = []
    
    # æ·»åŠ  BOS token
    ids.append(self.encode_special("<|bos|>"))
    mask.append(0)  # BOS ä¸å‚ä¸ loss
    
    for message in conversation["messages"]:
        role = message["role"]
        content = message["content"]
        
        if role == "user":
            # User message: å…¨éƒ¨ mask=0
            ids.extend(self.encode_special("<|user_start|>"))
            ids.extend(self.encode(content))
            ids.extend(self.encode_special("<|user_end|>"))
            mask.extend([0] * (len(ids) - len(mask)))
        
        elif role == "assistant":
            # Assistant message: åªæœ‰ content éƒ¨åˆ† mask=1
            ids.append(self.encode_special("<|assistant_start|>"))
            mask.append(0)  # start token ä¸å‚ä¸ loss
            
            content_ids = self.encode(content)
            ids.extend(content_ids)
            mask.extend([1] * len(content_ids))  # â† å…³é”®ï¼åªæœ‰è¿™é‡Œæ˜¯ 1
            
            ids.append(self.encode_special("<|assistant_end|>"))
            mask.append(1)  # end token å‚ä¸ loss
    
    return ids, mask
```

#### Loss è®¡ç®—è¿‡ç¨‹

```python
# ä» chat_sft.py
def sft_data_generator(dataset, batch_size):
    batch = []
    for conversation in dataset:
        ids, mask = tokenizer.render_conversation(conversation)
        batch.append((ids, mask))
        
        if len(batch) == batch_size:
            # Collate æˆå¼ é‡
            inputs = ...   # (B, T)
            targets = ...  # (B, T)
            
            # å…³é”®ï¼šå°† mask=0 çš„ä½ç½®è®¾ä¸º -1ï¼ˆignore indexï¼‰
            for i, (ids, mask) in enumerate(batch):
                row_targets = ids[1:]  # shift right
                mask_tensor = mask[1:]
                row_targets[mask_tensor == 0] = -1  # â† è®¾ä¸º ignore index
                targets[i] = row_targets
            
            yield inputs, targets
```

**CrossEntropyLoss çš„å¤„ç†**ï¼š
```python
# PyTorch å†…éƒ¨
loss = F.cross_entropy(
    logits.view(-1, vocab_size),  # (B*T, V)
    targets.view(-1),              # (B*T,)
    ignore_index=-1                # â† targets=-1 çš„ä½ç½®ä¸è®¡ç®— loss
)
```

**Mask æœºåˆ¶çš„æ•ˆæœ**ï¼š
- âœ… **åªå­¦ä¹ ç”Ÿæˆ**ï¼šæ¨¡å‹åªåœ¨ assistant çš„å›å¤ä¸Šè®¡ç®—æ¢¯åº¦
- âœ… **ä¿ç•™ä¸Šä¸‹æ–‡**ï¼šuser çš„è¾“å…¥ä»ç„¶å‚ä¸ forward passï¼Œæä¾›ä¸Šä¸‹æ–‡
- âœ… **ç²¾ç¡®æ§åˆ¶**ï¼šå¯ä»¥çµæ´»æ§åˆ¶å“ªäº› token å‚ä¸è®­ç»ƒï¼ˆå¦‚å·¥å…·è°ƒç”¨ï¼‰

### éªŒè¯æ•°æ®

**æ•°æ®é›†ï¼šSmolTalkï¼ˆæµ‹è¯•é›†ï¼‰**

```python
# ä» chat_sft.py
val_ds = SmolTalk(split="test")  # 24K å¯¹è¯
```

**ä¸ºä»€ä¹ˆåªç”¨ SmolTalkï¼Ÿ**
- ğŸ“Š **é€šç”¨æ€§**ï¼šSmolTalk æ¶µç›–å„ç§å¯¹è¯åœºæ™¯
- ğŸ“Š **å¤§è§„æ¨¡**ï¼š24K å¯¹è¯è¶³å¤Ÿè¯„ä¼°æ¨¡å‹çš„å¯¹è¯èƒ½åŠ›
- ğŸ“Š **å¿«é€Ÿè¯„ä¼°**ï¼šä¸éœ€è¦è¿è¡Œæ…¢é€Ÿçš„ç”Ÿæˆå¼è¯„ä¼°

#### è¯„ä¼°æŒ‡æ ‡

##### 1. Validation Lossï¼ˆæ¯ 100 æ­¥ï¼‰

```python
# ä» chat_sft.py
eval_every = 100
eval_steps = 100

# è¯„ä¼°è¿‡ç¨‹
for _ in range(eval_steps):
    val_inputs, val_targets = next(val_loader)
    with torch.no_grad():
        loss = model(val_inputs, val_targets)
    losses.append(loss)

val_loss = torch.stack(losses).mean()
```

##### 2. Task Accuracyï¼ˆæ¯ 200 æ­¥ï¼‰

```python
# ä» chat_sft.py
eval_metrics_every = 200
eval_metrics_max_problems = 1024

metrics = {
    "mmlu_acc": run_chat_eval("MMLU", ...),
    "arc_easy_acc": run_chat_eval("ARC-Easy", ...),
    "arc_challenge_acc": run_chat_eval("ARC-Challenge", ...),
    "gsm8k_maj1_acc": run_chat_eval("GSM8K", ..., num_samples=1),
    "gsm8k_maj16_acc": run_chat_eval("GSM8K", ..., num_samples=16),
}
```

**è¯„ä¼°ä»»åŠ¡è¯¦æƒ…**ï¼š

| ä»»åŠ¡ | è¯„ä¼°ç±»å‹ | æ ·æœ¬æ•° | æŒ‡æ ‡å«ä¹‰ |
|------|---------|--------|---------|
| MMLU | Categorical | 1024 | 57ä¸ªå­¦ç§‘çš„å‡†ç¡®ç‡ |
| ARC-Easy | Categorical | 1024 | å°å­¦ç§‘å­¦æ¨ç†å‡†ç¡®ç‡ |
| ARC-Challenge | Categorical | 1024 | ä¸­å­¦ç§‘å­¦æ¨ç†å‡†ç¡®ç‡ |
| GSM8K (maj@1) | Generative | 1024 | å•æ¬¡é‡‡æ ·çš„å‡†ç¡®ç‡ |
| GSM8K (maj@16) | Generative | 1024 | 16æ¬¡é‡‡æ ·çš„å¤šæ•°æŠ•ç¥¨å‡†ç¡®ç‡ |

**Categorical vs Generative**ï¼š
- **Categorical**ï¼šæ¯”è¾ƒ logitsï¼Œä¸éœ€è¦é‡‡æ ·ï¼Œé€Ÿåº¦å¿«ï¼ˆ~15 åˆ†é’Ÿï¼‰
- **Generative**ï¼šéœ€è¦ç”Ÿæˆå®Œæ•´å›ç­”ï¼Œè§£æç­”æ¡ˆï¼Œé€Ÿåº¦æ…¢ï¼ˆ~45 åˆ†é’Ÿï¼‰

### è®­ç»ƒé…ç½®

```python
# chat_sft.py é»˜è®¤é…ç½®
device_batch_size = 4         # å° batch sizeï¼ˆé¿å… OOMï¼‰
target_examples_per_step = 32 # æ¯æ­¥å¤„ç† 32 ä¸ªå¯¹è¯
num_epochs = 1                # 1 epoch

# å­¦ä¹ ç‡ï¼ˆéå¸¸å°ï¼ï¼‰
unembedding_lr = 0.004
embedding_lr = 0.2
matrix_lr = 0.02
init_lr_frac = 0.02          # â† å…³é”®ï¼åªç”¨ 2% çš„ LR
# å®é™… LR = åŸºç¡€ LR Ã— 0.02
# ä¾‹å¦‚ï¼šmatrix_lr = 0.02 Ã— 0.02 = 0.0004

weight_decay = 0.0

# å­¦ä¹ ç‡è°ƒåº¦ï¼ˆçº¿æ€§è¡°å‡åˆ° 0ï¼‰
def get_lr_multiplier(it):
    return 1.0 - it / num_iterations
```

**ä¸ºä»€ä¹ˆç”¨è¿™ä¹ˆå°çš„å­¦ä¹ ç‡ï¼Ÿ**
- ğŸ¯ **é˜²æ­¢é—å¿˜**ï¼šæ¨¡å‹åœ¨ Base å’Œ Mid é˜¶æ®µå·²ç»å­¦åˆ°å¾ˆå¤šçŸ¥è¯†
- ğŸ¯ **ç²¾ç»†è°ƒæ•´**ï¼šSFT åªæ˜¯å¾®è°ƒå¯¹è¯æ ¼å¼å’Œè¾“å‡ºé£æ ¼
- ğŸ¯ **å°æ•°æ®é›†**ï¼š23K æ ·æœ¬å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆ

**è®­ç»ƒé•¿åº¦è®¡ç®—**ï¼š
```python
dataset_size = 23000
target_examples_per_step = 32
num_epochs = 1

num_iterations = (dataset_size // target_examples_per_step) * num_epochs
# = (23000 // 32) * 1
# = 718 steps
```

---

## ğŸ“Š ç¬¬å››é˜¶æ®µï¼šRL Trainingï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰

### è®­ç»ƒæ•°æ®

**æ•°æ®é›†ï¼šGSM8Kï¼ˆè®­ç»ƒé›†ï¼‰**

```python
# ä» chat_rl.py
train_task = GSM8K(subset="main", split="train")
# 7473 ä¸ªæ•°å­¦é—®é¢˜
```

#### æ•°æ®è§„æ¨¡
- **é—®é¢˜æ•°é‡**ï¼š7473 ä¸ªå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **æ ¼å¼**ï¼šå•è½®é—®ç­”ï¼ˆuser æé—®ï¼Œassistant å›ç­”ï¼‰
- **éš¾åº¦**ï¼šéœ€è¦å¤šæ­¥æ¨ç†å’Œå·¥å…·ä½¿ç”¨

#### æ•°æ®ç‰¹ç‚¹

**GSM8K é—®é¢˜ç¤ºä¾‹**ï¼š
```
Question: Janet's ducks lay 16 eggs per day. She eats three for breakfast 
every morning and bakes muffins for her friends every day with four. 
She sells the remainder at the farmers' market daily for $2 per fresh 
duck egg. How much in dollars does she make every day at the farmers' market?

Answer: 18
```

**å…³é”®ç‰¹æ€§**ï¼š
- ğŸ§® **å¤šæ­¥æ¨ç†**ï¼šéœ€è¦åˆ†è§£é—®é¢˜ï¼Œé€æ­¥è®¡ç®—
- ğŸ› ï¸ **å·¥å…·ä½¿ç”¨**ï¼šéœ€è¦è°ƒç”¨ `<tool>calculator(...)</tool>`
- ğŸ“ **è‡ªç„¶è¯­è¨€**ï¼šç­”æ¡ˆéœ€è¦ç”¨è‡ªç„¶è¯­è¨€è§£é‡Šæ¨ç†è¿‡ç¨‹
- âœ… **æ˜ç¡®ç­”æ¡ˆ**ï¼šæ¯ä¸ªé—®é¢˜æœ‰å”¯ä¸€çš„æ•°å€¼ç­”æ¡ˆ

### RL è®­ç»ƒæœºåˆ¶

#### æ ¸å¿ƒæ€æƒ³ï¼šGRPOï¼ˆç®€åŒ–ç‰ˆï¼‰

```python
"""
GRPO = Group Relative Policy Optimization

ç®€åŒ–ç‰ˆï¼š
1. åˆ é™¤ trust regionï¼ˆæ—  KL æ•£åº¦çº¦æŸï¼‰
2. On-policyï¼ˆæ— éœ€ PPO ratio+clipï¼‰
3. Token-level ä¼˜åŠ¿å½’ä¸€åŒ–ï¼ˆGAPO é£æ ¼ï¼‰
4. åªç”¨ (r - mu) ä½œä¸º advantageï¼ˆä¸é™¤ä»¥ sigmaï¼‰
"""
```

#### è®­ç»ƒæµç¨‹

```python
# ä» chat_rl.py
examples_per_step = 16  # æ¯æ­¥å¤„ç† 16 ä¸ªé—®é¢˜
num_samples = 16        # æ¯ä¸ªé—®é¢˜ç”Ÿæˆ 16 ä¸ªå›ç­”

@torch.no_grad()
def get_batch():
    # éå†è®­ç»ƒé›†
    for example_idx in range(ddp_rank, len(train_task), ddp_world_size):
        
        # 1. è·å–é—®é¢˜
        conversation = train_task[example_idx]
        
        # 2. Tokenizeï¼ˆä¿ç•™ <|assistant_start|>ï¼Œåˆ é™¤åé¢çš„å†…å®¹ï¼‰
        tokens = tokenizer.render_for_completion(conversation)
        prefix_length = len(tokens)
        
        # 3. ç”Ÿæˆ 16 ä¸ªå›ç­”ï¼ˆæ‰¹é‡ç”Ÿæˆï¼Œé¿å… OOMï¼‰
        model.eval()
        generated_token_sequences = []
        masks = []
        
        for sampling_step in range(num_samples // device_batch_size):
            seed = hash((step, example_idx, sampling_step)) & 0x7FFFFFFF
            
            sequences, masks_batch = engine.generate_batch(
                tokens,
                num_samples=device_batch_size,
                max_tokens=max_new_tokens,
                temperature=1.0,  # â† é«˜æ¸©åº¦ï¼Œé¼“åŠ±æ¢ç´¢
                top_k=50,
                seed=seed
            )
            
            generated_token_sequences.extend(sequences)
            masks.extend(masks_batch)
        
        # 4. è®¡ç®—æ¯ä¸ªå›ç­”çš„å¥–åŠ±
        rewards = []
        for sample_tokens in generated_token_sequences:
            generated_tokens = sample_tokens[prefix_length:]
            generated_text = tokenizer.decode(generated_tokens)
            
            # å¥–åŠ±å‡½æ•°ï¼šç­”æ¡ˆæ˜¯å¦æ­£ç¡®
            reward = train_task.reward(conversation, generated_text)
            rewards.append(reward)
        
        # 5. Padding ä½¿æ‰€æœ‰åºåˆ—ç­‰é•¿
        max_length = max(len(seq) for seq in generated_token_sequences)
        padded_sequences = [
            seq + [pad_token] * (max_length - len(seq))
            for seq in generated_token_sequences
        ]
        padded_masks = [
            mask + [0] * (max_length - len(mask))
            for mask in masks
        ]
        
        # 6. è½¬æ¢ä¸ºå¼ é‡
        ids = torch.tensor(padded_sequences, device=device)  # (16, T)
        mask_ids = torch.tensor(padded_masks, device=device)  # (16, T)
        
        inputs = ids[:, :-1]   # (16, T-1)
        targets = ids[:, 1:].clone()
        targets[mask_ids[:, 1:] == 0] = -1  # mask out
        
        rewards = torch.tensor(rewards, device=device)  # (16,)
        
        # 7. è®¡ç®— advantageï¼ˆåªå‡å‡å€¼ï¼Œä¸é™¤æ ‡å‡†å·®ï¼‰
        mu = rewards.mean()
        advantages = rewards - mu  # (16,)
        
        # 8. Yield batch
        yield sequences, inputs, targets, rewards, advantages
```

#### å¥–åŠ±å‡½æ•°

```python
# ä» tasks/gsm8k.py
def reward(self, problem, completion):
    """
    è¿”å›ï¼š1.0ï¼ˆæ­£ç¡®ï¼‰æˆ– 0.0ï¼ˆé”™è¯¯ï¼‰
    """
    # 1. ä» completion ä¸­æå–ç­”æ¡ˆ
    predicted_answer = self.extract_answer(completion)
    
    # 2. è·å–æ­£ç¡®ç­”æ¡ˆ
    correct_answer = problem["answer"]
    
    # 3. æ¯”è¾ƒï¼ˆéœ€è¦å¤„ç†æ•°å€¼æ ¼å¼ï¼šé€—å·ã€å°æ•°ç‚¹ç­‰ï¼‰
    return 1.0 if self.answers_match(predicted_answer, correct_answer) else 0.0

def extract_answer(self, completion):
    """
    ä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æå–ç­”æ¡ˆ
    æ”¯æŒå¤šç§æ ¼å¼ï¼š
    - "The answer is 42"
    - "#### 42"
    - "<tool>calculator(...)</tool> = 42"
    """
    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
    patterns = [
        r"#### (\d+)",
        r"The answer is (\d+)",
        r"= (\d+)",
    ]
    for pattern in patterns:
        match = re.search(pattern, completion)
        if match:
            return match.group(1)
    return None
```

#### Policy Gradient æ›´æ–°

```python
# ä» chat_rl.py
# Training loop
for step in range(num_steps):
    
    # 1. è·å– batchï¼ˆåŒ…å« rolloutsï¼‰
    sequences, inputs, targets, rewards, advantages = next(get_batch())
    # inputs: (16, T-1)
    # targets: (16, T-1)ï¼Œmask å
    # rewards: (16,)
    # advantages: (16,)
    
    # 2. Forward passï¼ˆè®¡ç®— log probsï¼‰
    model.train()
    logits = model(inputs)  # (16, T-1, V)
    
    log_probs = F.log_softmax(logits, dim=-1)  # (16, T-1, V)
    
    # 3. æ”¶é›† targets ä½ç½®çš„ log probs
    # log_probs_taken: (16, T-1)
    log_probs_taken = log_probs.gather(
        dim=-1,
        index=targets.unsqueeze(-1).clamp(min=0)
    ).squeeze(-1)
    
    # 4. Mask out padding å’Œ prompt
    mask = (targets != -1).float()  # (16, T-1)
    log_probs_taken = log_probs_taken * mask
    
    # 5. Policy Gradient Loss
    # L = -mean(log_prob * advantage)
    advantages_expanded = advantages.unsqueeze(-1)  # (16, 1)
    
    # Token-level loss
    token_losses = -log_probs_taken * advantages_expanded  # (16, T-1)
    
    # åªå¯¹é mask çš„ token æ±‚å‡å€¼
    loss = (token_losses * mask).sum() / mask.sum()
    
    # 6. Backward + Optimizer step
    loss.backward()
    
    # Gradient accumulation
    if (step + 1) % grad_accum_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**Policy Gradient çš„ç›´è§‰**ï¼š
- ğŸ¯ **Advantage > 0**ï¼šå¥–åŠ±é«˜äºå¹³å‡ â†’ å¢å¤§è¯¥ trajectory çš„æ¦‚ç‡
- ğŸ¯ **Advantage < 0**ï¼šå¥–åŠ±ä½äºå¹³å‡ â†’ å‡å°è¯¥ trajectory çš„æ¦‚ç‡
- ğŸ¯ **Token-level**ï¼šæ¯ä¸ª token éƒ½ç”¨åŒä¸€ä¸ª advantageï¼Œç®€åŒ–è®¡ç®—

### éªŒè¯æ•°æ®

**æ•°æ®é›†ï¼šGSM8Kï¼ˆæµ‹è¯•é›†ï¼‰**

```python
# ä» chat_rl.py
val_task = GSM8K(subset="main", split="test")
# 1319 ä¸ªé—®é¢˜
```

#### è¯„ä¼°æŒ‡æ ‡ï¼šPass@k

**å®šä¹‰**ï¼šä» k æ¬¡é‡‡æ ·ä¸­ï¼Œè‡³å°‘æœ‰ 1 æ¬¡æ­£ç¡®çš„æ¦‚ç‡ã€‚

**è®¡ç®—å…¬å¼**ï¼š
```
Pass@k = Î£ [1 if any(samples) is correct else 0] / num_examples
```

**è¯„ä¼°è¿‡ç¨‹**ï¼š

```python
# ä» chat_rl.py
def run_gsm8k_eval(
    task,
    tokenizer,
    engine,
    max_examples=400,
    num_samples=16,
    temperature=1.0,
):
    correct_counts = {1: 0, 4: 0, 16: 0}
    total = 0
    
    for problem in task[:max_examples]:
        conversation = problem
        tokens = tokenizer.render_for_completion(conversation)
        
        # ç”Ÿæˆ num_samples ä¸ªå›ç­”
        sequences, _ = engine.generate_batch(
            tokens,
            num_samples=num_samples,
            max_tokens=256,
            temperature=temperature,
            top_k=50,
        )
        
        # è¯„ä¼°æ¯ä¸ªå›ç­”
        is_correct = []
        for seq in sequences:
            generated_text = tokenizer.decode(seq[len(tokens):])
            reward = task.reward(conversation, generated_text)
            is_correct.append(reward == 1.0)
        
        # è®¡ç®— Pass@kï¼ˆk = 1, 4, 16ï¼‰
        correct_counts[1] += int(is_correct[0])  # Pass@1 = ç¬¬ 1 æ¬¡æ­£ç¡®
        correct_counts[4] += int(any(is_correct[:4]))  # Pass@4
        correct_counts[16] += int(any(is_correct[:16]))  # Pass@16
        
        total += 1
    
    return {
        "pass@1": correct_counts[1] / total,
        "pass@4": correct_counts[4] / total,
        "pass@16": correct_counts[16] / total,
    }
```

**Pass@k çš„æ„ä¹‰**ï¼š
- ğŸ“Š **Pass@1**ï¼šæ¨¡å‹çš„"æœ€ä½³çŒœæµ‹"å‡†ç¡®ç‡ï¼ˆç±»ä¼¼ greedy decodingï¼‰
- ğŸ“Š **Pass@4**ï¼šç»™æ¨¡å‹ 4 æ¬¡æœºä¼šï¼Œèƒ½å¦æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ
- ğŸ“Š **Pass@16**ï¼šç»™æ¨¡å‹ 16 æ¬¡æœºä¼šï¼Œæµ‹è¯•æ¢ç´¢èƒ½åŠ›
- ğŸ“Š **è¶‹åŠ¿**ï¼šPass@1 < Pass@4 < Pass@16ï¼ˆæ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›ï¼‰

**è¯„ä¼°é…ç½®**ï¼š
```python
eval_every = 60              # æ¯ 60 æ­¥è¯„ä¼°ä¸€æ¬¡
eval_examples = 400          # ä½¿ç”¨ 400 ä¸ªæµ‹è¯•æ ·æœ¬
num_samples = 16             # æ¯ä¸ªé—®é¢˜ç”Ÿæˆ 16 æ¬¡
temperature = 1.0            # é«˜æ¸©åº¦ï¼Œä¿æŒæ¢ç´¢æ€§
```

### è®­ç»ƒé…ç½®

```python
# chat_rl.py é»˜è®¤é…ç½®
device_batch_size = 8        # æ¯å¼ å¡çš„ batch size
examples_per_step = 16       # æ¯æ­¥å¤„ç† 16 ä¸ªé—®é¢˜
num_samples = 16             # æ¯ä¸ªé—®é¢˜ç”Ÿæˆ 16 ä¸ªå›ç­”
max_new_tokens = 256         # æœ€å¤§ç”Ÿæˆé•¿åº¦
temperature = 1.0            # é‡‡æ ·æ¸©åº¦ï¼ˆé«˜æ¸©åº¦ï¼Œé¼“åŠ±æ¢ç´¢ï¼‰
top_k = 50                   # Top-k é‡‡æ ·

# å­¦ä¹ ç‡ï¼ˆä¸ SFT ç›¸ä¼¼ï¼‰
unembedding_lr = 0.004
embedding_lr = 0.2
matrix_lr = 0.02
weight_decay = 0.0
init_lr_frac = 0.05          # 5% çš„åŸºç¡€ LR

num_epochs = 1               # 1 epoch over GSM8K
```

**è®­ç»ƒé•¿åº¦è®¡ç®—**ï¼š
```python
dataset_size = 7473
examples_per_step = 16
num_epochs = 1

num_steps = (dataset_size // examples_per_step) * num_epochs
# = (7473 // 16) * 1
# = 467 steps
```

**ä¸ºä»€ä¹ˆç”¨é«˜æ¸©åº¦ï¼ˆtemperature=1.0ï¼‰ï¼Ÿ**
- ğŸ¯ **é¼“åŠ±æ¢ç´¢**ï¼šç”Ÿæˆå¤šæ ·åŒ–çš„å›ç­”
- ğŸ¯ **Off-policy å­¦ä¹ **ï¼šå³ä½¿æŸäº›å›ç­”ä¸å¥½ï¼Œä¹Ÿèƒ½ä»ä¸­å­¦ä¹ ï¼ˆé€šè¿‡è´Ÿ advantageï¼‰
- ğŸ¯ **é¿å…æ¨¡å¼å´©å¡Œ**ï¼šé˜²æ­¢æ¨¡å‹åªç”Ÿæˆä¸€ç§ç±»å‹çš„å›ç­”

---

## ğŸ“Š å››é˜¶æ®µæ•°æ®æµè½¬å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Base Training (é¢„è®­ç»ƒ)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è®­ç»ƒæ•°æ®: FineWeb-Edu (100B tokens, 1822 shards)            â”‚
â”‚ éªŒè¯æ•°æ®: FineWeb-Edu (10M tokens, 1 shard)                 â”‚
â”‚ è¯„ä¼°æŒ‡æ ‡: BPB + CORE Metric (9 tasks)                       â”‚
â”‚ å­¦ä¹ ç›®æ ‡: è¯­è¨€å»ºæ¨¡ + åŸºç¡€æ¨ç†èƒ½åŠ›                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Mid Training (ä¸­é—´è®­ç»ƒ)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è®­ç»ƒæ•°æ®: 7 ä»»åŠ¡æ··åˆ (850K å¯¹è¯)                            â”‚
â”‚   - SmolTalk: 460K (é€šç”¨å¯¹è¯)                               â”‚
â”‚   - MMLU: 100K (å¤šé€‰é¢˜)                                     â”‚
â”‚   - GSM8K: 8K (æ•°å­¦æ¨ç†)                                    â”‚
â”‚   - Identity: 2K (èº«ä»½è®¤çŸ¥)                                 â”‚
â”‚   - SimpleSpelling: 200K (æ‹¼å†™)                             â”‚
â”‚   - SpellingBee: 80K (å­—æ¯è®¡æ•°)                             â”‚
â”‚ éªŒè¯æ•°æ®: 3 ä»»åŠ¡æ··åˆ (30K å¯¹è¯)                             â”‚
â”‚ è¯„ä¼°æŒ‡æ ‡: BPB                                                â”‚
â”‚ å­¦ä¹ ç›®æ ‡: å¯¹è¯æ ¼å¼ + ä»»åŠ¡èƒ½åŠ› + å·¥å…·ä½¿ç”¨                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SFT Training (ç›‘ç£å¾®è°ƒ)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è®­ç»ƒæ•°æ®: 7 ä»»åŠ¡æ··åˆ (23K å¯¹è¯ï¼Œç²¾ç®€ 97%)                   â”‚
â”‚   - ARC: 3.4K (ç§‘å­¦æ¨ç†)                                    â”‚
â”‚   - GSM8K: 8K (æ•°å­¦æ¨ç†)                                    â”‚
â”‚   - SmolTalk: 10K (é€šç”¨å¯¹è¯)                                â”‚
â”‚   - Identity: 1K (èº«ä»½è®¤çŸ¥)                                 â”‚
â”‚   - Spelling: 600 (æ‹¼å†™+è®¡æ•°)                               â”‚
â”‚ éªŒè¯æ•°æ®: SmolTalk (24K å¯¹è¯)                               â”‚
â”‚ è¯„ä¼°æŒ‡æ ‡: Loss + MMLU/ARC/GSM8K å‡†ç¡®ç‡                      â”‚
â”‚ å­¦ä¹ ç›®æ ‡: æŒ‡ä»¤éµå¾ª + è¾“å‡ºæ ¼å¼æ§åˆ¶                            â”‚
â”‚ æ ¸å¿ƒæŠ€æœ¯: Mask æœºåˆ¶ (åªåœ¨ assistant å›å¤ä¸Šè®¡ç®— loss)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RL Training (å¼ºåŒ–å­¦ä¹ )                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è®­ç»ƒæ•°æ®: GSM8K (7.5K é—®é¢˜)                                 â”‚
â”‚ éªŒè¯æ•°æ®: GSM8K (1.3K é—®é¢˜)                                 â”‚
â”‚ è¯„ä¼°æŒ‡æ ‡: Pass@k (k=1,4,16)                                 â”‚
â”‚ å­¦ä¹ ç›®æ ‡: å¤šæ­¥æ¨ç† + è¯•é”™æ¢ç´¢                                â”‚
â”‚ æ ¸å¿ƒæŠ€æœ¯: Policy Gradient (æ¯é¢˜é‡‡æ · 16 æ¬¡)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š æ•°æ®é‡å˜åŒ–è¶‹åŠ¿

### Token / æ ·æœ¬æ•°é‡å¯¹æ¯”

| é˜¶æ®µ | è®­ç»ƒæ•°æ®é‡ | éªŒè¯æ•°æ®é‡ | æ•°æ®ç±»å‹ |
|------|-----------|-----------|---------|
| Base | 100B tokens | 10M tokens | çº¯æ–‡æœ¬ |
| Mid | 850K å¯¹è¯ â‰ˆ 1.7B tokens | 30K å¯¹è¯ â‰ˆ 60M tokens | ç»“æ„åŒ–å¯¹è¯ |
| SFT | 23K å¯¹è¯ â‰ˆ 46M tokens | 24K å¯¹è¯ â‰ˆ 48M tokens | ç»“æ„åŒ–å¯¹è¯ |
| RL | 7.5K é—®é¢˜ Ã— 16 æ ·æœ¬ = 120K æ ·æœ¬ | 1.3K é—®é¢˜ Ã— 16 æ ·æœ¬ | å•è½®é—®ç­” |

### å­¦ä¹ ç‡å˜åŒ–è¶‹åŠ¿

| é˜¶æ®µ | Matrix LR | Embedding LR | Unembedding LR | LR å€æ•° |
|------|-----------|-------------|---------------|--------|
| Base | 0.02 | 0.2 | 0.004 | 1.0 |
| Mid | 0.02 | 0.2 | 0.004 | 1.0 |
| SFT | 0.02 | 0.2 | 0.004 | **0.02** |
| RL | 0.02 | 0.2 | 0.004 | **0.05** |

**å­¦ä¹ ç‡ç­–ç•¥**ï¼š
- Base/Midï¼šå¤§ LRï¼Œå¿«é€Ÿå­¦ä¹ 
- SFTï¼šæå° LRï¼ˆ2%ï¼‰ï¼Œé˜²æ­¢é—å¿˜
- RLï¼šå° LRï¼ˆ5%ï¼‰ï¼Œç²¾ç»†è°ƒæ•´æ¨ç†èƒ½åŠ›

### è¯„ä¼°æŒ‡æ ‡æ¼”å˜

```
Base: BPB + CORE Metric
  â†“
  è¯„ä¼°è¯­è¨€å»ºæ¨¡èƒ½åŠ›å’ŒåŸºç¡€æ¨ç†
  
Mid: BPB
  â†“
  è¯„ä¼°å¯¹è¯æ ¼å¼çš„æŒæ¡ç¨‹åº¦
  
SFT: Loss + Task Accuracy (MMLU/ARC/GSM8K)
  â†“
  è¯„ä¼°æŒ‡ä»¤éµå¾ªå’Œæ ¼å¼æ§åˆ¶
  
RL: Pass@k (k=1,4,16)
  â†“
  è¯„ä¼°å¤šæ­¥æ¨ç†å’Œæ¢ç´¢èƒ½åŠ›
```

---

## ğŸ¯ æ ¸å¿ƒå‘ç°ä¸æ´å¯Ÿ

### 1. æ•°æ®è§„æ¨¡çš„é˜¶æ¢¯å¼é€’å‡

**è§„å¾‹**ï¼šBase (100B) â†’ Mid (1.7B) â†’ SFT (46M) â†’ RL (on-policy ç”Ÿæˆ)

**åŸå› **ï¼š
- ğŸ” **çŸ¥è¯†ç§¯ç´¯**ï¼šBase éœ€è¦å¤§é‡æ•°æ®å­¦ä¹ è¯­è¨€å’Œä¸–ç•ŒçŸ¥è¯†
- ğŸ” **èƒ½åŠ›è¿ç§»**ï¼šMid å¤ç”¨ Base çš„çŸ¥è¯†ï¼Œåªéœ€å­¦ä¹ æ–°æ ¼å¼
- ğŸ” **ç²¾ç»†è°ƒæ•´**ï¼šSFT åªéœ€å°‘é‡é«˜è´¨é‡æ•°æ®è°ƒæ•´è¾“å‡ºé£æ ¼
- ğŸ” **åœ¨çº¿å­¦ä¹ **ï¼šRL é€šè¿‡ on-policy é‡‡æ ·ï¼Œæ— éœ€ç¦»çº¿æ•°æ®

### 2. ä»»åŠ¡æ··åˆçš„ç­–ç•¥æ¼”å˜

**Base â†’ Mid**ï¼š
- ä»çº¯æ–‡æœ¬ â†’ ç»“æ„åŒ–å¯¹è¯
- å¼•å…¥ä»»åŠ¡æ•°æ®ï¼ˆMMLUã€GSM8Kã€Spellingï¼‰
- æ•™ä¼šæ¨¡å‹å·¥å…·ä½¿ç”¨

**Mid â†’ SFT**ï¼š
- å¤§å¹…å‡å°‘æ•°æ®é‡ï¼ˆ97% å‡å°‘ï¼‰
- å»é™¤å¤§è§„æ¨¡æ‹¼å†™ä»»åŠ¡ï¼ˆ200K â†’ 300ï¼‰
- å¼•å…¥ ARCï¼Œå¼ºåŒ–æ¨ç†èƒ½åŠ›
- ä½¿ç”¨ Mask æœºåˆ¶ï¼Œåªåœ¨ assistant å›å¤ä¸Šå­¦ä¹ 

**SFT â†’ RL**ï¼š
- èšç„¦å•ä¸€ä»»åŠ¡ï¼ˆGSM8Kï¼‰
- ä»ç›‘ç£å­¦ä¹  â†’ å¼ºåŒ–å­¦ä¹ 
- ä»å›ºå®šç­”æ¡ˆ â†’ è¯•é”™æ¢ç´¢

### 3. è¯„ä¼°æŒ‡æ ‡çš„ç²¾ç»†åŒ–

**BPB**ï¼š
- é€‚ç”¨äº Base å’Œ Mid é˜¶æ®µ
- ä¼˜åŠ¿ï¼štokenizer æ— å…³ï¼Œå¯æ¯”è¾ƒä¸åŒæ¨¡å‹
- å±€é™ï¼šåªèƒ½è¯„ä¼°è¯­è¨€å»ºæ¨¡ï¼Œä¸èƒ½è¯„ä¼°æ¨ç†èƒ½åŠ›

**CORE Metric**ï¼š
- é€‚ç”¨äº Base é˜¶æ®µ
- ä¼˜åŠ¿ï¼šå¤šä»»åŠ¡ç»¼åˆè¯„ä¼°ï¼Œæ—©æœŸå‘ç°æ¨ç†èƒ½åŠ›
- æˆæœ¬ï¼šéœ€è¦ 162MB æ•°æ®ï¼Œè¯„ä¼°è¾ƒæ…¢

**Task Accuracy**ï¼š
- é€‚ç”¨äº SFT é˜¶æ®µ
- ä¼˜åŠ¿ï¼šç›´æ¥è¯„ä¼°ä»»åŠ¡è¡¨ç°
- åˆ†ç±»ï¼šCategoricalï¼ˆå¿«ï¼‰vs Generativeï¼ˆæ…¢ï¼‰

**Pass@k**ï¼š
- é€‚ç”¨äº RL é˜¶æ®µ
- ä¼˜åŠ¿ï¼šè¯„ä¼°æ¢ç´¢èƒ½åŠ›ï¼Œè€Œéå•æ¬¡å‡†ç¡®ç‡
- æ´å¯Ÿï¼šPass@16 >> Pass@1 è¯´æ˜æ¨¡å‹æœ‰å¾ˆå¼ºçš„æ¢ç´¢èƒ½åŠ›

### 4. Mask æœºåˆ¶çš„é‡è¦æ€§

**é—®é¢˜**ï¼šå¦‚ä½•è®©æ¨¡å‹åªå­¦ä¹ ç”Ÿæˆå›ç­”ï¼Œè€Œä¸æ˜¯è®°ä½é—®é¢˜ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# User çš„è¾“å…¥ï¼šmask = 0ï¼ˆä¸è®¡ç®— lossï¼‰
# Assistant çš„å›å¤ï¼šmask = 1ï¼ˆè®¡ç®— lossï¼‰
targets[mask == 0] = -1  # ignore_index
```

**æ•ˆæœ**ï¼š
- âœ… æ¨¡å‹åªåœ¨ assistant å›å¤ä¸Šæ›´æ–°æ¢¯åº¦
- âœ… ä¿ç•™ user è¾“å…¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- âœ… é˜²æ­¢æ¨¡å‹è®°ä½è®­ç»ƒæ•°æ®çš„é—®é¢˜

### 5. å¼ºåŒ–å­¦ä¹ çš„ç®€åŒ–è®¾è®¡

**GRPO çš„ç®€åŒ–**ï¼š
- âŒ åˆ é™¤ KL æ•£åº¦çº¦æŸï¼ˆtrust regionï¼‰
- âŒ åˆ é™¤ PPO ratio + clip
- âœ… ä¿ç•™ token-level ä¼˜åŠ¿å½’ä¸€åŒ–
- âœ… ä½¿ç”¨ (r - mu) è€Œé (r - mu) / sigma

**æ•ˆæœ**ï¼š
- ğŸš€ **è®­ç»ƒç¨³å®š**ï¼šOn-policy å­¦ä¹ ï¼Œæ— éœ€æ‹…å¿ƒç­–ç•¥åç§»
- ğŸš€ **å®ç°ç®€å•**ï¼šåªéœ€è¦è®¡ç®— policy gradient
- ğŸš€ **æ•ˆæœè‰¯å¥½**ï¼šPass@k æŒç»­æå‡

---

## ğŸ“‹ å¿«é€Ÿå‚è€ƒè¡¨

### è¿è¡Œå‘½ä»¤

```bash
# Base Training (8 GPUs)
torchrun --standalone --nproc_per_node=8 -m scripts.base_train \
    --run=base_run \
    --depth=20 \
    --device_batch_size=32

# Mid Training (8 GPUs)
torchrun --standalone --nproc_per_node=8 -m scripts.mid_train \
    --run=mid_run \
    --model_tag=d20 \
    --step=4500 \
    --device_batch_size=32

# SFT Training (8 GPUs)
torchrun --standalone --nproc_per_node=8 -m scripts.chat_sft \
    --run=sft_run \
    --source=mid \
    --model_tag=d20 \
    --device_batch_size=4

# RL Training (8 GPUs)
torchrun --standalone --nproc_per_node=8 -m scripts.chat_rl \
    --run=rl_run \
    --source=sft \
    --device_batch_size=8
```

### è¯„ä¼°å‘½ä»¤

```bash
# Base Model Evaluation
python -m scripts.base_eval --model_tag=d20 --step=4500

# Chat Model Evaluation
python -m scripts.chat_eval --source=sft --model_tag=d20

# GSM8K Pass@k Evaluation
# (é›†æˆåœ¨ RL è®­ç»ƒä¸­ï¼Œæ¯ 60 æ­¥è‡ªåŠ¨è¿è¡Œ)
```

### æ•°æ®å‡†å¤‡

```bash
# ä¸‹è½½ Base è®­ç»ƒæ•°æ®ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰
# FineWeb-Edu ä¼šåœ¨è®­ç»ƒæ—¶æŒ‰éœ€ä¸‹è½½

# ä¸‹è½½ CORE Metric è¯„ä¼°æ•°æ®
# è¯„ä¼°æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ eval_bundle.zip

# å‡†å¤‡ Identity Conversationsï¼ˆéœ€è¦æ‰‹åŠ¨åˆ›å»ºï¼‰
# æ–‡ä»¶ä½ç½®: <base_dir>/identity_conversations.jsonl
```

---

## ğŸ“ æ€»ç»“

nanochat é¡¹ç›®çš„å››é˜¶æ®µè®­ç»ƒå±•ç¤ºäº†ç°ä»£ LLM è®­ç»ƒçš„å®Œæ•´æµç¨‹ï¼š

1. **Base Training**ï¼šåœ¨æµ·é‡æ–‡æœ¬ä¸Šå­¦ä¹ è¯­è¨€å’ŒçŸ¥è¯†
2. **Mid Training**ï¼šå­¦ä¹ å¯¹è¯æ ¼å¼å’Œä»»åŠ¡èƒ½åŠ›
3. **SFT Training**ï¼šç²¾ç»†è°ƒæ•´è¾“å‡ºæ ¼å¼å’ŒæŒ‡ä»¤éµå¾ª
4. **RL Training**ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡æ¨ç†å’Œæ¢ç´¢èƒ½åŠ›

æ¯ä¸ªé˜¶æ®µéƒ½æœ‰æ˜ç¡®çš„æ•°æ®æ¥æºã€è¯„ä¼°æŒ‡æ ‡å’Œè®­ç»ƒç›®æ ‡ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚

**å…³é”®è®¾è®¡åŸåˆ™**ï¼š
- âœ… **æ•°æ®è´¨é‡ > æ•°é‡**ï¼šSFT åªç”¨ 23K æ ·æœ¬ï¼Œä½†æ•ˆæœæ˜¾è‘—
- âœ… **å­¦ä¹ ç‡é€’å‡**ï¼šBase (1.0x) â†’ SFT (0.02x)ï¼Œé˜²æ­¢é—å¿˜
- âœ… **è¯„ä¼°æŒ‡æ ‡æ¼”å˜**ï¼šä» BPB â†’ Accuracy â†’ Pass@kï¼Œé€æ­¥ç²¾ç»†åŒ–
- âœ… **æ¸è¿›å¼å­¦ä¹ **ï¼šæ¯ä¸ªé˜¶æ®µéƒ½åŸºäºå‰ä¸€é˜¶æ®µçš„ checkpoint

è¿™ä»½æŠ¥å‘Šæ¶µç›–äº†æ‰€æœ‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¸Œæœ›èƒ½å¸®åŠ©ä½ å…¨é¢ç†è§£ nanochat çš„è®­ç»ƒæµç¨‹ï¼ğŸš€
